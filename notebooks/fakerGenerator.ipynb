{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create big data with faker and use generator\n",
    "### Tuesday: 27-02-2024\n",
    "\n",
    "* Read the data normally\n",
    "\n",
    "* Read the data using generator \n",
    "\n",
    "* Compare time and memory usage\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Measuring Data using own utility\n",
      ">>>Measuring fakerHandler_read_csv\n",
      "Memory used: 0.0 MB\n",
      "Time taken: 3.70639705657959 seconds\n",
      "\n",
      ">>>Measuring fakerHandler_read_csv_generator\n",
      "Memory used: 0.0 MB\n",
      "Time taken: 0.0 seconds\n",
      "\n",
      "-Measuring Data using cProfile\n",
      ">>>Measuring fakerHandler_read_csv\n",
      "fakerHandler_read_csv = <function fakerHandler_read_csv at 0x0000019C2E65D630>\n",
      "         50 function calls in 3.080 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 37 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.079    3.079 4191684558.py:25(fakerHandler_read_csv)\n",
      "        1    0.026    0.026    3.079    3.079 fakerHandler.py:5(readCSV)\n",
      "        1    1.729    1.729    1.729    1.729 {method 'splitlines' of 'str' objects}\n",
      "        1    1.165    1.165    1.324    1.324 {method 'read' of '_io.TextIOWrapper' objects}\n",
      "        1    0.000    0.000    0.159    0.159 codecs.py:319(decode)\n",
      "        1    0.159    0.159    0.159    0.159 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
      "\n",
      "\n",
      "\n",
      ">>>Measuring fakerHandler_read_csv_generator\n",
      "fakerHandler_read_csv_generator = <function fakerHandler_read_csv_generator at 0x0000019C2E65EB00>\n",
      "         34 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 21 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:107(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:117(init)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:136(load_stats)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "        1    0.000    0.000    0.000    0.000 4191684558.py:31(fakerHandler_read_csv_generator)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        1    0.000    0.000    0.000    0.000 cProfile.py:50(create_stats)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import pandas as pd\n",
    "from cProfile import Profile\n",
    "from pstats import Stats\n",
    "from faker import Faker\n",
    "from handlers.fakerHandler import FakerHandler\n",
    "from Utils import Utils as utils\n",
    "\n",
    "fake = Faker()\n",
    "dataSize = 10000000\n",
    "fake_user_filepath = \"../data/csv/fake_users_\"+str(dataSize)+\".csv\"\n",
    "\n",
    "def createFakeData(filepath, size):\n",
    "    if not os.path.exists(filepath):\n",
    "        data = {\n",
    "            'Name': [fake.name() for _ in range(size)],\n",
    "            'Address': [fake.address().replace('\\n', ', ') for _ in range(dataSize)],\n",
    "            'Email': [fake.email() for _ in range(size)]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "def fakerHandler_read_csv():\n",
    "    fH = FakerHandler()\n",
    "    lines = fH.readCSV(fake_user_filepath)\n",
    "    #print(lines[0])\n",
    "    #print(lines[1])\n",
    "\n",
    "def fakerHandler_read_csv_generator():\n",
    "    fH = FakerHandler()\n",
    "    line = fH.readCSVGenerator(fake_user_filepath)\n",
    "    #print(next(line))\n",
    "    #print(next(line))\n",
    "\n",
    "# Create fake data\n",
    "createFakeData(fake_user_filepath, dataSize)\n",
    "\n",
    "# Measure the functions using own utility\n",
    "print(\"-Measuring Data using own utility\")\n",
    "print(\">>>Measuring fakerHandler_read_csv\")\n",
    "utils.measure_function(fakerHandler_read_csv)\n",
    "print(\">>>Measuring fakerHandler_read_csv_generator\")\n",
    "utils.measure_function(fakerHandler_read_csv_generator)\n",
    "\n",
    "# Measure the functions with cProfile\n",
    "print(\"-Measuring Data using cProfile\")\n",
    "print(\">>>Measuring fakerHandler_read_csv\")\n",
    "with Profile() as pr:\n",
    "    fakerHandler_read_csv()\n",
    "    print(f\"{fakerHandler_read_csv = }\")\n",
    "    (\n",
    "        Stats(pr)\n",
    "        .strip_dirs()\n",
    "        .sort_stats('cumulative')\n",
    "        .print_stats(10)\n",
    "    )\n",
    "\n",
    "print(\"\\n\"+\">>>Measuring fakerHandler_read_csv_generator\")\n",
    "with Profile() as pr:\n",
    "    fakerHandler_read_csv_generator()\n",
    "    print(f\"{fakerHandler_read_csv_generator = }\")\n",
    "    (\n",
    "        Stats(pr)\n",
    "        .strip_dirs()\n",
    "        .sort_stats('cumulative')\n",
    "        .print_stats(10)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Use big data and \"Do something with it\"\n",
    "### Tuesday: 27-02-2024\n",
    "\n",
    "* Count names normally\n",
    "\n",
    "* Count names using generator\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Measuring Data using own utility\n",
      ">>>Measuring countNames\n",
      "Number of John:  637201\n",
      "Memory used: 0.01953125 MB\n",
      "Time taken: 4.594434976577759 seconds\n",
      "\n",
      ">>>Measuring countNamesGenerator\n",
      "Number of John:  637201\n",
      "Memory used: 0.0 MB\n",
      "Time taken: 2.551888942718506 seconds\n",
      "\n",
      "-Measuring Data using cProfile\n",
      ">>>Measuring fakerHandler_read_csv\n",
      "fakerHandler_read_csv = <function fakerHandler_read_csv at 0x0000019C2E65D7E0>\n",
      "         50 function calls in 3.131 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 37 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.131    3.131 4191684558.py:25(fakerHandler_read_csv)\n",
      "        1    0.027    0.027    3.131    3.131 fakerHandler.py:5(readCSV)\n",
      "        1    1.800    1.800    1.800    1.800 {method 'splitlines' of 'str' objects}\n",
      "        1    1.153    1.153    1.303    1.303 {method 'read' of '_io.TextIOWrapper' objects}\n",
      "        1    0.000    0.000    0.150    0.150 codecs.py:319(decode)\n",
      "        1    0.150    0.150    0.150    0.150 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
      "\n",
      "\n",
      "\n",
      ">>>Measuring fakerHandler_read_csv_generator\n",
      "fakerHandler_read_csv_generator = <function fakerHandler_read_csv_generator at 0x0000019C2E65E9E0>\n",
      "         34 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 21 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:107(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:117(init)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:136(load_stats)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "        1    0.000    0.000    0.000    0.000 4191684558.py:31(fakerHandler_read_csv_generator)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        1    0.000    0.000    0.000    0.000 cProfile.py:50(create_stats)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Utils import Utils as utils\n",
    "\n",
    "def countNames(name):\n",
    "    fH = FakerHandler()\n",
    "    count = 0\n",
    "    lines = fH.getNameData(fake_user_filepath, name)\n",
    "    for _ in lines:\n",
    "        count += 1\n",
    "    print(\"Number of \"+name+\": \", count)\n",
    "\n",
    "def countNamesGenerator(name):\n",
    "    fH = FakerHandler()\n",
    "    count = 0\n",
    "    lines = fH.getNameDataGenerator(fake_user_filepath, name)\n",
    "    for _ in lines:\n",
    "        count += 1\n",
    "    print(\"Number of \"+name+\": \", count)\n",
    "\n",
    "\n",
    "# Measure the functions using own utility\n",
    "print(\"-Measuring Data using own utility\")\n",
    "print(\">>>Measuring countNames\")\n",
    "utils.measure_function(countNames, \"John\")\n",
    "print(\">>>Measuring countNamesGenerator\")\n",
    "utils.measure_function(countNamesGenerator, \"John\")\n",
    "\n",
    "# Measure the functions with cProfile\n",
    "print(\"-Measuring Data using cProfile\")\n",
    "print(\">>>Measuring fakerHandler_read_csv\")\n",
    "with Profile() as pr:\n",
    "    fakerHandler_read_csv()\n",
    "    print(f\"{fakerHandler_read_csv = }\")\n",
    "    (\n",
    "        Stats(pr)\n",
    "        .strip_dirs()\n",
    "        .sort_stats('cumulative')\n",
    "        .print_stats(10)\n",
    "    )\n",
    "\n",
    "print(\"\\n\"+\">>>Measuring fakerHandler_read_csv_generator\")\n",
    "with Profile() as pr:\n",
    "    fakerHandler_read_csv_generator()\n",
    "    print(f\"{fakerHandler_read_csv_generator = }\")\n",
    "    (\n",
    "        Stats(pr)\n",
    "        .strip_dirs()\n",
    "        .sort_stats('cumulative')\n",
    "        .print_stats(10)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lets test a multithreaded example\n",
    "### Wednesday: 28-02-2024\n",
    "\n",
    "* Count names from 2 files normally\n",
    "\n",
    "* Count names from 2 files using generators and threaded\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Measuring Data using own utility\n",
      ">>>Measuring countNames\n",
      "Number of John:  69995\n",
      "Memory used: 1.29296875 MB\n",
      "Time taken: 0.36900949478149414 seconds\n",
      "\n",
      ">>>Measuring countThreadedNamesGenerator\n",
      "Number of John:  69995\n",
      "Memory used: 0.0 MB\n",
      "Time taken: 0.29004859924316406 seconds\n",
      "\n",
      "-Measuring Data using cProfile\n",
      ">>>Measuring countNames\n",
      "Number of John:  69995\n",
      "countNames = <function countNames at 0x0000019C56B53130>\n",
      "         70099 function calls in 0.384 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 38 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.027    0.027    0.384    0.384 1114827413.py:4(countNames)\n",
      "        2    0.091    0.046    0.357    0.179 fakerHandler.py:28(getNameData)\n",
      "        2    0.126    0.063    0.144    0.072 {method 'read' of '_io.TextIOWrapper' objects}\n",
      "        2    0.117    0.059    0.117    0.059 {method 'splitlines' of 'str' objects}\n",
      "        2    0.000    0.000    0.018    0.009 codecs.py:319(decode)\n",
      "        2    0.018    0.009    0.018    0.009 {built-in method _codecs.utf_8_decode}\n",
      "    69995    0.005    0.000    0.005    0.000 {method 'append' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        6    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "\n",
      "\n",
      ">>>Measuring countNames multithreaded\n",
      "Number of John:  69995\n",
      "countThreadedNamesGenerator = <function countThreadedNamesGenerator at 0x0000019C56B53A30>\n",
      "         280 function calls in 0.296 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 81 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.296    0.296 1114827413.py:17(countThreadedNamesGenerator)\n",
      "       21    0.296    0.014    0.296    0.014 {method 'acquire' of '_thread.lock' objects}\n",
      "        5    0.000    0.000    0.296    0.059 threading.py:288(wait)\n",
      "        2    0.000    0.000    0.295    0.148 _base.py:430(result)\n",
      "        2    0.000    0.000    0.001    0.000 thread.py:161(submit)\n",
      "        2    0.000    0.000    0.001    0.000 thread.py:180(_adjust_thread_count)\n",
      "        2    0.000    0.000    0.001    0.000 threading.py:916(start)\n",
      "        2    0.000    0.000    0.001    0.000 threading.py:589(wait)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:648(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 thread.py:216(shutdown)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Utils import Utils as utils\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def countNames(name):\n",
    "    fH = FakerHandler()\n",
    "    fake_user_filepath = \"../data/csv/fake_users_1000000.csv\"\n",
    "    fake_user_filepath_2 = \"../data/csv/fake_users_100000.csv\"\n",
    "    count = 0\n",
    "    lines = fH.getNameData(fake_user_filepath, name)\n",
    "    for _ in lines:\n",
    "        count += 1\n",
    "    lines = fH.getNameData(fake_user_filepath_2, name)\n",
    "    for _ in lines:\n",
    "        count += 1\n",
    "    print(\"Number of \"+name+\": \", count)\n",
    "\n",
    "def countThreadedNamesGenerator(name):\n",
    "    fH = FakerHandler()\n",
    "    fake_user_filepath = \"../data/csv/fake_users_1000000.csv\"\n",
    "    fake_user_filepath_2 = \"../data/csv/fake_users_100000.csv\"\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        future1 = executor.submit(fH.countNames, fake_user_filepath, name)\n",
    "        future2 = executor.submit(fH.countNames, fake_user_filepath_2, name)\n",
    "\n",
    "        count1 = future1.result()\n",
    "        count2 = future2.result()\n",
    "\n",
    "    total_count = count1 + count2\n",
    "    print(\"Number of \"+name+\": \", total_count)\n",
    "\n",
    "# Measure the functions using own utility\n",
    "print(\"-Measuring Data using own utility\")\n",
    "print(\">>>Measuring countNames\")\n",
    "utils.measure_function(countNames, \"John\")\n",
    "print(\">>>Measuring countThreadedNamesGenerator\")\n",
    "utils.measure_function(countThreadedNamesGenerator, \"John\")\n",
    "\n",
    "# Measure the functions with cProfile\n",
    "print(\"-Measuring Data using cProfile\")\n",
    "print(\">>>Measuring countNames\")\n",
    "with Profile() as pr:\n",
    "    countNames(\"John\")\n",
    "    print(f\"{countNames = }\")\n",
    "    (\n",
    "        Stats(pr)\n",
    "        .strip_dirs()\n",
    "        .sort_stats('cumulative')\n",
    "        .print_stats(10)\n",
    "    )\n",
    "\n",
    "print(\">>>Measuring countNames multithreaded\")\n",
    "with Profile() as pr:\n",
    "    countThreadedNamesGenerator(\"John\")\n",
    "    print(f\"{countThreadedNamesGenerator = }\")\n",
    "    (\n",
    "        Stats(pr)\n",
    "        .strip_dirs()\n",
    "        .sort_stats('cumulative')\n",
    "        .print_stats(10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lets combine what we learned\n",
    "### Wednesday: 28-02-2024\n",
    "\n",
    "* Count names from all csv files efficiently\n",
    "\n",
    "* Use generators\n",
    "\n",
    "* Use threads\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Measuring Data using own utility\n",
      ">>>Measuring countThreadedNamesGenerator\n",
      "File names to count from:  ['fake_users', 'fake_users_10.csv', 'fake_users_100.csv', 'fake_users_1000.csv', 'fake_users_10000.csv', 'fake_users_100000.csv', 'fake_users_1000000.csv', 'fake_users_10000000.csv']\n",
      "Number of workers:  8\n",
      "Number of John:  707883\n",
      "Memory used: 0.0 MB\n",
      "Time taken: 3.173654794692993 seconds\n",
      "\n",
      "-Measuring Data using cProfile\n",
      ">>>Measuring countNames multithreaded\n",
      "File names to count from:  ['fake_users', 'fake_users_10.csv', 'fake_users_100.csv', 'fake_users_1000.csv', 'fake_users_10000.csv', 'fake_users_100000.csv', 'fake_users_1000000.csv', 'fake_users_10000000.csv']\n",
      "Number of workers:  8\n",
      "Number of John:  707883\n",
      "countThreadedNamesGenerator = <function countThreadedNamesGenerator at 0x0000019C56B53C70>\n",
      "         905 function calls in 2.976 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 94 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    2.976    2.976 2661567677.py:5(countThreadedNamesGenerator)\n",
      "       46    2.975    0.065    2.975    0.065 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    2.974    2.974 _base.py:648(__exit__)\n",
      "        1    0.000    0.000    2.974    2.974 thread.py:216(shutdown)\n",
      "        5    0.000    0.000    2.974    0.595 threading.py:1064(join)\n",
      "        6    0.000    0.000    2.974    0.496 threading.py:1102(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.002    0.002 2661567677.py:18(<listcomp>)\n",
      "        8    0.000    0.000    0.002    0.000 thread.py:161(submit)\n",
      "        8    0.000    0.000    0.002    0.000 thread.py:180(_adjust_thread_count)\n",
      "        5    0.000    0.000    0.001    0.000 threading.py:916(start)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from Utils import Utils as utils\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def countThreadedNamesGenerator(name):\n",
    "    fH = FakerHandler()\n",
    "    directory = \"../data/csv/\"\n",
    "    file_paths = [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "    \n",
    "    # Print file names\n",
    "    file_names = [os.path.basename(file_path) for file_path in file_paths]\n",
    "    print(\"File names to count from: \", file_names)\n",
    "\n",
    "    num_workers = min(os.cpu_count(), len(file_paths)) # Limit workers to number of files or number of cores\n",
    "    print(\"Number of workers: \", num_workers)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(fH.countNames, file_path, name) for file_path in file_paths]\n",
    "\n",
    "    total_count = sum(future.result() for future in futures)\n",
    "    print(\"Number of \"+name+\": \", total_count)\n",
    "\n",
    "# Measure the functions using own utility\n",
    "print(\"-Measuring Data using own utility\")\n",
    "print(\">>>Measuring countThreadedNamesGenerator\")\n",
    "utils.measure_function(countThreadedNamesGenerator, \"John\")\n",
    "\n",
    "# Measure the functions with cProfile\n",
    "print(\"-Measuring Data using cProfile\")\n",
    "print(\">>>Measuring countNames multithreaded\")\n",
    "with Profile() as pr:\n",
    "    countThreadedNamesGenerator(\"John\")\n",
    "    print(f\"{countThreadedNamesGenerator = }\")\n",
    "    (\n",
    "        Stats(pr)\n",
    "        .strip_dirs()\n",
    "        .sort_stats('cumulative')\n",
    "        .print_stats(10)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
